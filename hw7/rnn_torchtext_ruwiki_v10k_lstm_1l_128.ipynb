{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import math \n",
    "\n",
    "from torchtext import data, datasets\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda:6', 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init cuda\n",
    "device = \"cuda:6\" if torch.cuda.is_available() else \"cpu\"\n",
    "idevice = 6 if torch.cuda.is_available() else -1\n",
    "torch.cuda.set_device(idevice)\n",
    "device, idevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field()\n",
    "PATH = Path('./wikitext/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sequence_length = 30\n",
    "grad_clip = 0.1\n",
    "lr = 4.\n",
    "best_val_loss = None\n",
    "log_interval = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets.language_modeling import LanguageModelingDataset\n",
    "\n",
    "class WikiTextRu(LanguageModelingDataset):\n",
    "\n",
    "    urls = ['http://files.deeppavlov.ai/datasets/wikitext_ru.zip']\n",
    "    name = 'wikitext_ru'\n",
    "    dirname = 'wikitext_ru'\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, text_field, root='.data', \n",
    "               train='ru.wiki.train.txt', validation='ru.wiki.valid.txt', test='ru.wiki.test.txt',  **kwargs):\n",
    "\n",
    "        return super().splits(text_field=text_field, root=root, \n",
    "                              train=train, validation=validation, test=test, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def iters(cls, batch_size=32, bptt_len=35, device=0, root='.data', vectors=None, **kwargs):\n",
    "       \n",
    "        TEXT = data.Field()\n",
    "        train, val, test = cls.splits(TEXT, root=root, **kwargs)\n",
    "        TEXT.build_vocab(train, vectors=vectors)\n",
    "\n",
    "        return data.BPTTIterator.splits((train, val, test), \n",
    "                                        batch_size=batch_size, bptt_len=bptt_len, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "\n",
    "class RuFastText(Vectors):\n",
    "\n",
    "    url_base = 'http://files.deeppavlov.ai/embeddings/ft_native_300_ru_wiki_lenta_nltk_word_tokenize/ft_native_300_ru_wiki_lenta_nltk_word_tokenize.vec'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        url = self.url_base\n",
    "        name = os.path.basename(url)\n",
    "        super().__init__(name, url=url, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 17.2 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ds, valid_ds, test_ds = WikiTextRu.splits(TEXT, root=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_vectors = RuFastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 15 s, total: 2min 30s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(train_ds, min_freq=30, max_size=10_000, vectors=ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntokens = len(TEXT.vocab)\n",
    "ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 µs, sys: 30 µs, total: 189 µs\n",
      "Wall time: 213 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loader, val_loader, test_loader = data.BPTTIterator.splits((train_ds, valid_ds, test_ds), \n",
    "                                        batch_sizes=(batch_size, batch_size, batch_size), \n",
    "                                        bptt_len=sequence_length, repeat=False, device=idevice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_type, emb_vectors, nhid, nlayers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        ntoken = emb_vectors.shape[0]\n",
    "        ninp = emb_vectors.shape[1]\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.encoder.weight.data.copy_(emb_vectors);\n",
    "        self.encoder.weight.requires_grad = False\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(ninp, nhid, nlayers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        emb = self.drop(self.encoder(x))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new(self.nlayers, bsz, self.nhid).zero_(),\n",
    "                    weight.new(self.nlayers, bsz, self.nhid).zero_())\n",
    "        else:\n",
    "            return weight.new(self.nlayers, bsz, self.nhid).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    ntokens = len(TEXT.vocab)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i, b in enumerate(data_loader):\n",
    "        data, targets = b.text, b.target\n",
    "        output, hidden = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        total_loss += len(data) * criterion(output_flat, targets.view(-1)).item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ntokens = len(TEXT.vocab) #len(corpus.dictionary)\n",
    "    for batch, b in enumerate(train_loader):\n",
    "        data, targets = b.text, b.target\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(data)\n",
    "        loss = criterion(output.view(-1, ntokens), targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), grad_clip)\n",
    "        for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_loader), lr, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n=50, temp=1.):\n",
    "    model.eval()\n",
    "    x = torch.rand(1, 1).mul(ntokens).long().to(device)\n",
    "    hidden = None\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        output, hidden = model(x, hidden)\n",
    "        s_weights = output.squeeze().data.div(temp).exp()\n",
    "        s_idx = torch.multinomial(s_weights, 1)[0]\n",
    "        x.data.fill_(s_idx)\n",
    "        s = TEXT.vocab.itos[s_idx]\n",
    "        out.append(s)\n",
    "    return ' '.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vectors = TEXT.vocab.vectors\n",
    "model = RNNModel('LSTM', emb_vectors, 128, 1, 0.0).to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:\n",
      " тюрьмы Алан галерее собственных финансовых полгода оставить принимали птица военная производству полк. Так кровь здания \n",
      "\n",
      "CPU times: user 5.39 ms, sys: 7.5 ms, total: 12.9 ms\n",
      "Wall time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    print('sample:\\n', generate(15), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 10000/49916 batches | lr 4.00 | loss  4.92 | ppl   136.85\n",
      "| epoch   1 | 20000/49916 batches | lr 4.00 | loss  4.48 | ppl    88.02\n",
      "| epoch   1 | 30000/49916 batches | lr 4.00 | loss  4.29 | ppl    72.75\n",
      "| epoch   1 | 40000/49916 batches | lr 4.00 | loss  4.18 | ppl    65.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | valid loss 122.43 | valid ppl 147687316997835539700604251822616840547712309802303488.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " , <unk> собой <unk> сборную национальной на четыре <unk> радио <unk> ( <unk> <unk> носителей <unk> <unk> , включая <unk> , <unk> <unk> морской <unk> на машине <unk> <unk> ) и <unk> <unk> <unk> <unk> <unk> , и Роберт им <unk> и <unk> на <unk> в <unk> . <eos> <eos> \n",
      "\n",
      "| epoch   2 | 10000/49916 batches | lr 4.00 | loss  4.06 | ppl    57.75\n",
      "| epoch   2 | 20000/49916 batches | lr 4.00 | loss  4.01 | ppl    55.29\n",
      "| epoch   2 | 30000/49916 batches | lr 4.00 | loss  3.98 | ppl    53.77\n",
      "| epoch   2 | 40000/49916 batches | lr 4.00 | loss  3.96 | ppl    52.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | valid loss 117.91 | valid ppl 1617141937072466984025015318065803496534007579934720.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " части Германии <unk> в уезде и <unk> Одна по <unk> с <unk> <unk> от 27 озёр ( от острова до 3 тыс. ) , дочерью 35 м над уровнем <unk> , который составляет 35 м ( HD ) . Более небольшими 22 находятся недалеко <unk> <unk> <unk> относятся к системе \n",
      "\n",
      "| epoch   3 | 10000/49916 batches | lr 4.00 | loss  3.92 | ppl    50.32\n",
      "| epoch   3 | 20000/49916 batches | lr 4.00 | loss  3.90 | ppl    49.30\n",
      "| epoch   3 | 30000/49916 batches | lr 4.00 | loss  3.89 | ppl    48.75\n",
      "| epoch   3 | 40000/49916 batches | lr 4.00 | loss  3.87 | ppl    48.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | valid loss 115.76 | valid ppl 188811435208295366126979037998904639014082034270208.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " » ( 1962 ) и <unk> <unk> » ( <unk> на <unk> , 2003 г. ) ; <unk> <unk> <unk> — <unk> В 1973 г. песня книги <unk> in <unk> Games » относится к <unk> и <unk> » <unk> . <eos> <eos> О историков при участии группы % особенно ; \n",
      "\n",
      "| epoch   4 | 10000/49916 batches | lr 4.00 | loss  3.85 | ppl    46.94\n",
      "| epoch   4 | 20000/49916 batches | lr 4.00 | loss  3.83 | ppl    46.27\n",
      "| epoch   4 | 30000/49916 batches | lr 4.00 | loss  3.83 | ppl    45.99\n",
      "| epoch   4 | 40000/49916 batches | lr 4.00 | loss  3.82 | ppl    45.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | valid loss 114.30 | valid ppl 43804141043332267788708753586994039748845402849280.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> <unk> <unk> упал <unk> района и <unk> . <eos> <eos> Для <unk> <unk> <unk> является <unk> <unk> у <unk> , но основанием <unk> для <unk> финансовой имеет свой <unk> для <unk> техники : <unk> ( с государством Корея в период , — <unk> ) , <unk> , развитие дела \n",
      "\n",
      "| epoch   5 | 10000/49916 batches | lr 4.00 | loss  3.80 | ppl    44.77\n",
      "| epoch   5 | 20000/49916 batches | lr 4.00 | loss  3.79 | ppl    44.26\n",
      "| epoch   5 | 30000/49916 batches | lr 4.00 | loss  3.79 | ppl    44.11\n",
      "| epoch   5 | 40000/49916 batches | lr 4.00 | loss  3.78 | ppl    43.77\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | valid loss 113.22 | valid ppl 14808130390237138862498712978900570664266272604160.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> <unk> <unk> <unk> все оставался золото <unk> <unk> памяти и <unk> <unk> <unk> <unk> лица . <eos> <eos> <unk> <unk> <eos> <eos> <unk> <unk> <unk> , <unk> <unk> очень <unk> <unk> < , в том числе рядом , параметры музыкантов на <unk> <unk> ( <unk> ) , <unk> <unk> \n",
      "\n",
      "| epoch   6 | 10000/49916 batches | lr 4.00 | loss  3.77 | ppl    43.20\n",
      "| epoch   6 | 20000/49916 batches | lr 4.00 | loss  3.76 | ppl    42.78\n",
      "| epoch   6 | 30000/49916 batches | lr 4.00 | loss  3.75 | ppl    42.70\n",
      "| epoch   6 | 40000/49916 batches | lr 4.00 | loss  3.75 | ppl    42.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | valid loss 112.34 | valid ppl 6170991182225779062579382490779636076294478757888.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> идею таким образом <unk> по направлению цикла , <unk> себя мне перед оба <unk> <unk> его было с большим обоих <unk> <unk> Потом ради этого <unk> <unk> <unk> <unk> , которые могли бы его <unk> <unk> использовать его назвать <unk> этот <unk> <unk> со своими работами , <unk> <unk> \n",
      "\n",
      "| epoch   7 | 10000/49916 batches | lr 4.00 | loss  3.74 | ppl    41.97\n",
      "| epoch   7 | 20000/49916 batches | lr 4.00 | loss  3.73 | ppl    41.62\n",
      "| epoch   7 | 30000/49916 batches | lr 4.00 | loss  3.73 | ppl    41.59\n",
      "| epoch   7 | 40000/49916 batches | lr 4.00 | loss  3.72 | ppl    41.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | valid loss 111.63 | valid ppl 3026044304105925803350175589185551725845922447360.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " была <unk> 18 января 2006 года компания <unk> , <unk> <unk> и <unk> <unk> , <unk> <unk> <unk> на тот момент в первый <unk> <unk> <unk> кампания на <unk> построены 200 <unk> Во время турнира завершилась <unk> <unk> против <unk> <unk> было <unk> возникновения <unk> рабочих <unk> . <eos> <eos> \n",
      "\n",
      "| epoch   8 | 10000/49916 batches | lr 4.00 | loss  3.71 | ppl    40.99\n",
      "| epoch   8 | 20000/49916 batches | lr 4.00 | loss  3.71 | ppl    40.68\n",
      "| epoch   8 | 30000/49916 batches | lr 4.00 | loss  3.71 | ppl    40.68\n",
      "| epoch   8 | 40000/49916 batches | lr 4.00 | loss  3.70 | ppl    40.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | valid loss 111.04 | valid ppl 1669563296592998170660801378140959094648604721152.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " и 10 церквей , общее <unk> ( установка <unk> ) . 1 марта 2000 года <unk> был присвоен <unk> <unk> всех <unk> ; бывший <unk> М. <unk> , что <unk> <unk> , <unk> соглашение со множеством сохранения и сама <unk> , одно место <unk> <unk> хозяйства , и он <unk> \n",
      "\n",
      "| epoch   9 | 10000/49916 batches | lr 4.00 | loss  3.69 | ppl    40.19\n",
      "| epoch   9 | 20000/49916 batches | lr 4.00 | loss  3.69 | ppl    39.92\n",
      "| epoch   9 | 30000/49916 batches | lr 4.00 | loss  3.69 | ppl    39.95\n",
      "| epoch   9 | 40000/49916 batches | lr 4.00 | loss  3.68 | ppl    39.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | valid loss 110.54 | valid ppl 1014830241565186136490383672198923940538211106816.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " священника <unk> особо <unk> Единственный была <unk> В нижней части ареала , д. <unk> в Греции , и была территория британского <unk> Этот приезжает была хорошо <unk> , однако они играли с 1907 . <eos> <eos> С <unk> года территория <unk> отличается <unk> \" <unk> \" в 12 году . \n",
      "\n",
      "| epoch  10 | 10000/49916 batches | lr 4.00 | loss  3.68 | ppl    39.54\n",
      "| epoch  10 | 20000/49916 batches | lr 4.00 | loss  3.67 | ppl    39.30\n",
      "| epoch  10 | 30000/49916 batches | lr 4.00 | loss  3.67 | ppl    39.35\n",
      "| epoch  10 | 40000/49916 batches | lr 4.00 | loss  3.67 | ppl    39.21\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | valid loss 110.12 | valid ppl 667193862209362113024836513921076166288176316416.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " эту журнал <unk> берега сразу понял в <unk> «Я для других европейских <unk> , чем его положения ) — последнего не <unk> с деятельностью , однако <unk> Ли проводить комиссия , с поддержкой <unk> решила Юлия <unk> и <unk> <unk> Тогда <unk> <unk> такие как один из песен компонентов и \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 | 10000/49916 batches | lr 4.00 | loss  3.66 | ppl    39.00\n",
      "| epoch  11 | 20000/49916 batches | lr 4.00 | loss  3.66 | ppl    38.78\n",
      "| epoch  11 | 30000/49916 batches | lr 4.00 | loss  3.66 | ppl    38.84\n",
      "| epoch  11 | 40000/49916 batches | lr 4.00 | loss  3.66 | ppl    38.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | valid loss 109.76 | valid ppl 467122626905963211447072252094134935169064239104.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> армии и младших — 14 ноября 1788 года <unk> становится деревней <unk> при <unk> 3 воздушной тела , приходилось <unk> <unk> , чтобы атаку с <unk> войсками ветра , — в Гран-при это возможность время нескольких отрасли <unk> <unk> его как с <unk> для <unk> <unk> <unk> и библиотеку \n",
      "\n",
      "| epoch  12 | 10000/49916 batches | lr 4.00 | loss  3.65 | ppl    38.55\n",
      "| epoch  12 | 20000/49916 batches | lr 4.00 | loss  3.65 | ppl    38.34\n",
      "| epoch  12 | 30000/49916 batches | lr 4.00 | loss  3.65 | ppl    38.41\n",
      "| epoch  12 | 40000/49916 batches | lr 4.00 | loss  3.65 | ppl    38.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | valid loss 109.45 | valid ppl 341671352924651908605680993589697505946138312704.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " Кузнецов художников Белоруссии ( 1962 ) , <unk> молодёжной » , в <unk> <unk> Первая СССР в 1966 — 1997 гг. <unk> народной , <unk> <unk> … российской <unk> вспоминал раз и утвердил принять , что военную эту всё своё значение <unk> <unk> , как и большинство <unk> <unk> <unk> \n",
      "\n",
      "| epoch  13 | 10000/49916 batches | lr 4.00 | loss  3.64 | ppl    38.15\n",
      "| epoch  13 | 20000/49916 batches | lr 4.00 | loss  3.64 | ppl    37.96\n",
      "| epoch  13 | 30000/49916 batches | lr 4.00 | loss  3.64 | ppl    38.04\n",
      "| epoch  13 | 40000/49916 batches | lr 4.00 | loss  3.64 | ppl    37.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | valid loss 109.18 | valid ppl 260625784101960090060209557848261351641106612224.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> Компания <unk> заметно <unk> более чем ещё 10 — 10 000 машин — разработанный высокой VI , по <unk> <unk> XI <unk> <unk> можно <unk> от <unk> <unk> дополнительные <unk> <unk> нечто вроде <unk> поверхность и <unk> <unk> в <unk> <unk> образования и технический . <eos> <eos> ООН услуг \n",
      "\n",
      "| epoch  14 | 10000/49916 batches | lr 4.00 | loss  3.63 | ppl    37.81\n",
      "| epoch  14 | 20000/49916 batches | lr 4.00 | loss  3.63 | ppl    37.62\n",
      "| epoch  14 | 30000/49916 batches | lr 4.00 | loss  3.63 | ppl    37.72\n",
      "| epoch  14 | 40000/49916 batches | lr 4.00 | loss  3.63 | ppl    37.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | valid loss 108.93 | valid ppl 203874756402237081339029236927971124923141718016.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> <unk> у неё » под названием <unk> . <eos> <eos> \" Марк <unk> РСФСР , основу которой сразу представители <unk> жизни в 1989 году . <eos> <unk> иногда также книги существенно <unk> , которые записаны митрополита <unk> ди <unk> и балета <unk> <unk> общий Софии не удалось , из-за \n",
      "\n",
      "| epoch  15 | 10000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.50\n",
      "| epoch  15 | 20000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.33\n",
      "| epoch  15 | 30000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.43\n",
      "| epoch  15 | 40000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | valid loss 108.72 | valid ppl 164168244246301261371104881895588033334530277376.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> числа <unk> группы <unk> опубликованы в финальном турнире <unk> <eos> 2. <unk> команда <unk> сборной Канады Сил года , «Манчестер Юнайтед » ( 1988 ) , и Олег <unk> двоих <unk> стал новым игроком <unk> <unk> » ( <unk> в сезон <unk> играх » , <unk> » ) . \n",
      "\n",
      "| epoch  16 | 10000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.24\n",
      "| epoch  16 | 20000/49916 batches | lr 4.00 | loss  3.61 | ppl    37.07\n",
      "| epoch  16 | 30000/49916 batches | lr 4.00 | loss  3.62 | ppl    37.17\n",
      "| epoch  16 | 40000/49916 batches | lr 4.00 | loss  3.61 | ppl    37.10\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | valid loss 108.52 | valid ppl 135422448481953832111538831066555336910161575936.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " . <eos> <eos> В 1959 году <unk> из <unk> , <unk> и <unk> <unk> в составе <unk> <unk> и <unk> <unk> <unk> <unk> <unk> <unk> <unk> поколения <unk> <unk> почти 50 млн фунтов и <unk> населения , <unk> <unk> государство <unk> и строительства словам <unk> столицы . <eos> <eos> В \n",
      "\n",
      "| epoch  17 | 10000/49916 batches | lr 4.00 | loss  3.61 | ppl    37.00\n",
      "| epoch  17 | 20000/49916 batches | lr 4.00 | loss  3.61 | ppl    36.83\n",
      "| epoch  17 | 30000/49916 batches | lr 4.00 | loss  3.61 | ppl    36.94\n",
      "| epoch  17 | 40000/49916 batches | lr 4.00 | loss  3.61 | ppl    36.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | valid loss 108.35 | valid ppl 113470084051165390004504469508058609153290010624.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> происхождения , премьера которой в <unk> обмен русского <unk> » ( <unk> » ) . Эти <unk> автобусов <unk> опубликовал участники <unk> на своей профессиональной продолжения художников , которая бюро Ивана создания плавания , заняв там в 1994 году , <unk> <unk> на территории Северного группы , в свою \n",
      "\n",
      "| epoch  18 | 10000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.78\n",
      "| epoch  18 | 20000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.62\n",
      "| epoch  18 | 30000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.73\n",
      "| epoch  18 | 40000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | valid loss 108.18 | valid ppl 96393012136135232051736788819639425166649327616.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " с первым и <unk> » от <unk> 30 июня , Xbox <unk> <unk> <unk> лет назад на <unk> компании с <unk> в <unk> » началась <unk> <unk> <unk> <unk> провёл в <unk> , где более <unk> <unk> Entertainment <unk> <unk> , благодаря новым им существенно . <eos> <eos> В августе \n",
      "\n",
      "| epoch  19 | 10000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.58\n",
      "| epoch  19 | 20000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.43\n",
      "| epoch  19 | 30000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.54\n",
      "| epoch  19 | 40000/49916 batches | lr 4.00 | loss  3.60 | ppl    36.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | valid loss 108.04 | valid ppl 83032405036030084740109015720359078627630907392.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " области . <eos> <eos> <unk> <unk> Сербской листьев ( <unk> ) казаки <unk> . <eos> <unk> , <unk> , <unk> комплекс <unk> , что не для <unk> В <unk> год <unk> <unk> также и питаются . <eos> <eos> Ему год <unk> : <unk> ( <unk> <unk> с 1972 ) , \n",
      "\n",
      "| epoch  20 | 10000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.40\n",
      "| epoch  20 | 20000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.25\n",
      "| epoch  20 | 30000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.37\n",
      "| epoch  20 | 40000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | valid loss 107.90 | valid ppl 72414895581257663147705917350371850105250643968.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> <unk> Ранее Смит был открыт среди всех <unk> обслуживания и <unk> в том , что военная некогда <unk> под командованием <unk> и <unk> <unk> <unk> <unk> , что титул <unk> <unk> <unk> <unk> <unk> <unk> . <eos> <eos> По оценкам , жители идти на следующий линии <unk> на <unk> \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 | 10000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.23\n",
      "| epoch  21 | 20000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.09\n",
      "| epoch  21 | 30000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.21\n",
      "| epoch  21 | 40000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.15\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | valid loss 107.77 | valid ppl 63710408183649785083231364540568976851759792128.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " на <unk> основе борьбы ( за отличие , мужество и героизм <unk> Григория <unk> армия , лейтенант иностранные <unk> выполнение заданий командования крестьян и <unk> <unk> ) <unk> <unk> <unk> и армии , не имея в себя <unk> вперёд , а карьеру сопротивления , <unk> <unk> <unk> его <unk> участвовать \n",
      "\n",
      "| epoch  22 | 10000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.08\n",
      "| epoch  22 | 20000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.93\n",
      "| epoch  22 | 30000/49916 batches | lr 4.00 | loss  3.59 | ppl    36.06\n",
      "| epoch  22 | 40000/49916 batches | lr 4.00 | loss  3.58 | ppl    36.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | valid loss 107.65 | valid ppl 56601667208827426098474502792057870896871768064.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " , в действительности защиты доходов полёта относится и <unk> войск » <unk> в <unk> году [ 50 <unk> человек , в <unk> заливе — <unk> <unk> из единственной <unk> районами , <unk> они <unk> Согласно <unk> <unk> , <unk> царя мир со стороны от <unk> городского <unk> , где умерла \n",
      "\n",
      "| epoch  23 | 10000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.93\n",
      "| epoch  23 | 20000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.79\n",
      "| epoch  23 | 30000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.92\n",
      "| epoch  23 | 40000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | valid loss 107.54 | valid ppl 50613257397616327056775983856244803178162290688.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " за счет средств <unk> . <eos> <eos> <eos> <unk> Иванов по <unk> и <unk> УК <unk> А. В. <unk> при самым <unk> <unk> , <unk> 130 членов <unk> в <unk> <unk> <unk> <unk> , главы у <unk> , <unk> Дэвид <unk> из <unk> и <unk> , как <unk> оставили на \n",
      "\n",
      "| epoch  24 | 10000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.80\n",
      "| epoch  24 | 20000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.66\n",
      "| epoch  24 | 30000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.79\n",
      "| epoch  24 | 40000/49916 batches | lr 4.00 | loss  3.58 | ppl    35.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | valid loss 107.43 | valid ppl 45536739546762798417810165879096354528714293248.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " , <unk> был концертный тур для известной , <unk> семь <unk> , <unk> в себя выступали <unk> этой фамилии , а в 1979 году оно <unk> был <unk> на <unk> Франсиско <unk> <unk> был избран <unk> <unk> В январе 1964 года назначен главным редактором издательства » . <unk> — В. \n",
      "\n",
      "| epoch  25 | 10000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.67\n",
      "| epoch  25 | 20000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.54\n",
      "| epoch  25 | 30000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.67\n",
      "| epoch  25 | 40000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | valid loss 107.34 | valid ppl 41295967052435272813422058789152159981704839168.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " правления <unk> <unk> <unk> с большинством французской армией <unk> В ходе возвращения <unk> в <unk> году семья <unk> два своих Иоганна <unk> с <unk> Дании \" и <unk> <unk> Четыре тысяч <unk> продолжили <unk> передал <unk> <unk> <unk> <unk> собор , а ныне сохранился в церкви. <unk> <unk> д ’ \n",
      "\n",
      "| epoch  26 | 10000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.55\n",
      "| epoch  26 | 20000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.42\n",
      "| epoch  26 | 30000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.55\n",
      "| epoch  26 | 40000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | valid loss 107.25 | valid ppl 37666171444751806335297737661599923213734772736.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> <unk> , нежели по <unk> <unk> , <unk> или <unk> <unk> в <unk> <unk> <unk> <unk> , <unk> — новые <unk> . <eos> <eos> Щит <unk> <unk> ( <unk> что ) . <unk> сильно <unk> <unk> . <eos> <eos> <unk> является <unk> <unk> <unk> <unk> <unk> ( для <unk> \n",
      "\n",
      "| epoch  27 | 10000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.44\n",
      "| epoch  27 | 20000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.31\n",
      "| epoch  27 | 30000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.44\n",
      "| epoch  27 | 40000/49916 batches | lr 4.00 | loss  3.57 | ppl    35.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | valid loss 107.16 | valid ppl 34518300021173679778917040729570614447219671040.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " : <unk> выражение в Италии Киевского <unk> Его академик <unk> <unk> <unk> пока описаны , который <unk> <unk> <unk> носить Израиль <unk> — тем одним участников <unk> , когда была <unk> , тогда соглашается ему , которое это <unk> и <unk> <unk> После этого д ’ <unk> вышла замуж за \n",
      "\n",
      "| epoch  28 | 10000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.34\n",
      "| epoch  28 | 20000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.21\n",
      "| epoch  28 | 30000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.34\n",
      "| epoch  28 | 40000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | valid loss 107.07 | valid ppl 31737111415018088274527526311716513414461259776.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " командующего » , <unk> задачу <unk> , и ноябре <unk> был выпущен в числе своих войск и <unk> в <unk> конце Красной Армии , однако генерала НКВД СССР с 31 марта 1942 года 1-я танковая бригада города <unk> , береговой 250 авиационного оказалась до 22 ноября 1941 года. <unk> через \n",
      "\n",
      "| epoch  29 | 10000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.24\n",
      "| epoch  29 | 20000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.11\n",
      "| epoch  29 | 30000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.24\n",
      "| epoch  29 | 40000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | valid loss 106.99 | valid ppl 29272095356262038815484525658620418701968539648.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " в <unk> районе <unk> <unk> был построен в 1868 году , но тот стал <unk> По приказу императора , с 1961 по 1932 годы <unk> <unk> тогда , <unk> <unk> замка относительно <unk> населения. Здесь <unk> владел <unk> С 1988 по 1888 , 1968 г. был разработан <unk> <unk> <unk> \n",
      "\n",
      "| epoch  30 | 10000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.14\n",
      "| epoch  30 | 20000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.02\n",
      "| epoch  30 | 30000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.15\n",
      "| epoch  30 | 40000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | valid loss 106.91 | valid ppl 27059517953887755514313621464084143422220271616.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " поднялся соответствующие <unk> . <eos> <eos> В 1949 году <unk> основной <unk> базой на <unk> <unk> <unk> <unk> поддержкой , что <unk> <unk> и СМИ о <unk> <unk> компании следует содержать <unk> » — <unk> , путём <unk> просто <unk> сознания ) , что <unk> для <unk> <unk> <unk> между \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 | 10000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.05\n",
      "| epoch  31 | 20000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.93\n",
      "| epoch  31 | 30000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.06\n",
      "| epoch  31 | 40000/49916 batches | lr 4.00 | loss  3.56 | ppl    35.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | valid loss 106.84 | valid ppl 25122954064470043124948056042779551615980404736.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " политике <unk> команды открыто в том , что он — тренер сборной <unk> . <eos> <eos> Он принимал участие в соревнованиях Армении , в том числе ещё три матча и в группы в Кубке <unk> чемпионате мира , а также в полуфинале победа состоялся 7 — 33 <unk> В связи \n",
      "\n",
      "| epoch  32 | 10000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.97\n",
      "| epoch  32 | 20000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.85\n",
      "| epoch  32 | 30000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.98\n",
      "| epoch  32 | 40000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | valid loss 106.77 | valid ppl 23400446940618309604546301014135875852006588416.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> с 2015 года проведена в последний раз в марте 2014 года , после <unk> в <unk> <unk> , она <unk> уже в статье <unk> <unk> в 8 <unk> Летом 1956 года вышел в первом туре » и установил первое место в списке крупнейших <unk> <unk> года » и дебютировал \n",
      "\n",
      "| epoch  33 | 10000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.89\n",
      "| epoch  33 | 20000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.77\n",
      "| epoch  33 | 30000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.90\n",
      "| epoch  33 | 40000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | valid loss 106.70 | valid ppl 21877219555030419727485359267932872091912634368.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " в состав , как имеющий уже к концу лета Шотландии в <unk> <unk> заняли <unk> на <unk> протеста до <unk> <unk> В нём последняя <unk> влияние на <unk> , в частности , были <unk> работы В 1941 году в <unk> <unk> <unk> о <unk> <unk> на местном <unk> <unk> заново \n",
      "\n",
      "| epoch  34 | 10000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.81\n",
      "| epoch  34 | 20000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.69\n",
      "| epoch  34 | 30000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.82\n",
      "| epoch  34 | 40000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | valid loss 106.64 | valid ppl 20534431922773217070053254185831730093985103872.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "sample:\n",
      " <unk> название <unk> артиллерийского <unk> Существует , <unk> для проверки <unk> веществ : <eos> <eos> <unk> и <unk> между <unk> с <unk> словами и 1 уровнем <unk> <unk> ( см. <unk> со скоростью 2 ) , к <unk> <unk> <unk> является <unk> часть <unk> обработки <unk> крылья сравнительно <unk> , \n",
      "\n",
      "| epoch  35 | 10000/49916 batches | lr 4.00 | loss  3.55 | ppl    34.73\n",
      "| epoch  35 | 20000/49916 batches | lr 4.00 | loss  3.54 | ppl    34.62\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 51):\n",
    "    train()\n",
    "    val_loss = evaluate(val_loader)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "        epoch, val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "    else:\n",
    "        # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "        lr /= 4.0\n",
    "    with torch.no_grad():\n",
    "        print('sample:\\n', generate(50), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
