{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"./MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:6\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST(PATH, train=True, download=True, transform=tfms)\n",
    "test_ds = datasets.MNIST(PATH, train=False, download=True, transform=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = data.DataLoader(train_ds, batch_size=64)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_size):\n",
    "        super().__init__()\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, lr=1e-4, l2=0.):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        self.loss_fn = F.nll_loss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, target):\n",
    "        self._loss = self.loss_fn(pred, target)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        model.optim.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = model.loss(output, target)\n",
    "        loss.backward()\n",
    "        model.optim.step()   \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss  {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader), model._loss.item())\n",
    "        print(line)\n",
    "    return model._loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, ds):\n",
    "    test_size = len(loader.sampler)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda l, c, p: ' ' + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += model.loss(output, target).item() # sum up batch loss\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += (pred == target).sum().item()\n",
    "    \n",
    "    test_loss /= test_size\n",
    "    correct_pct = correct / test_size\n",
    "    report = ''+ds+' set:\\n' + line(test_loss, correct, 100.0 * correct_pct) + '\\n'\n",
    "    \n",
    "    print(report)\n",
    "    return test_loss, correct_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, shape):\n",
    "    fig = plt.figure(figsize=shape[::-1], dpi=80)\n",
    "    for j in range(1, len(images) + 1):\n",
    "        ax = fig.add_subplot(shape[0], shape[1], j)\n",
    "        ax.matshow(images[j - 1, 0, :, :], cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(28*28).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [30016/60000 (100%)]\tLoss  0.266227\n",
      "Test set:\n",
      " Loss: 0.0057\tAccuracy: 8917/10000 (89%)\n",
      "\n",
      "Train Epoch: 2 [30016/60000 (100%)]\tLoss  0.175925\n",
      "Test set:\n",
      " Loss: 0.0046\tAccuracy: 9116/10000 (91%)\n",
      "\n",
      "Train Epoch: 3 [30016/60000 (100%)]\tLoss  0.119545\n",
      "Test set:\n",
      " Loss: 0.0040\tAccuracy: 9245/10000 (92%)\n",
      "\n",
      "Train Epoch: 4 [30016/60000 (100%)]\tLoss  0.079860\n",
      "Test set:\n",
      " Loss: 0.0036\tAccuracy: 9333/10000 (93%)\n",
      "\n",
      "Train Epoch: 5 [30016/60000 (100%)]\tLoss  0.056426\n",
      "Test set:\n",
      " Loss: 0.0032\tAccuracy: 9390/10000 (94%)\n",
      "\n",
      "Train Epoch: 6 [30016/60000 (100%)]\tLoss  0.044370\n",
      "Test set:\n",
      " Loss: 0.0029\tAccuracy: 9433/10000 (94%)\n",
      "\n",
      "Train Epoch: 7 [30016/60000 (100%)]\tLoss  0.037945\n",
      "Test set:\n",
      " Loss: 0.0027\tAccuracy: 9489/10000 (95%)\n",
      "\n",
      "Train Epoch: 8 [30016/60000 (100%)]\tLoss  0.034029\n",
      "Test set:\n",
      " Loss: 0.0024\tAccuracy: 9528/10000 (95%)\n",
      "\n",
      "Train Epoch: 9 [30016/60000 (100%)]\tLoss  0.032212\n",
      "Test set:\n",
      " Loss: 0.0023\tAccuracy: 9556/10000 (96%)\n",
      "\n",
      "Train Epoch: 10 [30016/60000 (100%)]\tLoss  0.030169\n",
      "Test set:\n",
      " Loss: 0.0021\tAccuracy: 9588/10000 (96%)\n",
      "\n",
      "Train Epoch: 11 [30016/60000 (100%)]\tLoss  0.027356\n",
      "Test set:\n",
      " Loss: 0.0020\tAccuracy: 9616/10000 (96%)\n",
      "\n",
      "Train Epoch: 12 [30016/60000 (100%)]\tLoss  0.026472\n",
      "Test set:\n",
      " Loss: 0.0019\tAccuracy: 9634/10000 (96%)\n",
      "\n",
      "Train Epoch: 13 [30016/60000 (100%)]\tLoss  0.025368\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9657/10000 (97%)\n",
      "\n",
      "Train Epoch: 14 [30016/60000 (100%)]\tLoss  0.024085\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9671/10000 (97%)\n",
      "\n",
      "Train Epoch: 15 [30016/60000 (100%)]\tLoss  0.023709\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9684/10000 (97%)\n",
      "\n",
      "Train Epoch: 16 [30016/60000 (100%)]\tLoss  0.023376\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9698/10000 (97%)\n",
      "\n",
      "Train Epoch: 17 [30016/60000 (100%)]\tLoss  0.022144\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9701/10000 (97%)\n",
      "\n",
      "Train Epoch: 18 [30016/60000 (100%)]\tLoss  0.021990\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9704/10000 (97%)\n",
      "\n",
      "Train Epoch: 19 [30016/60000 (100%)]\tLoss  0.020719\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9709/10000 (97%)\n",
      "\n",
      "Train Epoch: 20 [30016/60000 (100%)]\tLoss  0.019930\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 21 [30016/60000 (100%)]\tLoss  0.019182\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9710/10000 (97%)\n",
      "\n",
      "Train Epoch: 22 [30016/60000 (100%)]\tLoss  0.019045\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9712/10000 (97%)\n",
      "\n",
      "Train Epoch: 23 [30016/60000 (100%)]\tLoss  0.018721\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9720/10000 (97%)\n",
      "\n",
      "Train Epoch: 24 [30016/60000 (100%)]\tLoss  0.016801\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 25 [30016/60000 (100%)]\tLoss  0.017491\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9722/10000 (97%)\n",
      "\n",
      "Train Epoch: 26 [30016/60000 (100%)]\tLoss  0.016750\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 27 [30016/60000 (100%)]\tLoss  0.015907\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9721/10000 (97%)\n",
      "\n",
      "Train Epoch: 28 [30016/60000 (100%)]\tLoss  0.015343\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9723/10000 (97%)\n",
      "\n",
      "Train Epoch: 29 [30016/60000 (100%)]\tLoss  0.014960\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9719/10000 (97%)\n",
      "\n",
      "Train Epoch: 30 [30016/60000 (100%)]\tLoss  0.013939\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9720/10000 (97%)\n",
      "\n",
      "Train Epoch: 31 [30016/60000 (100%)]\tLoss  0.013319\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 32 [30016/60000 (100%)]\tLoss  0.012741\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9728/10000 (97%)\n",
      "\n",
      "Train Epoch: 33 [30016/60000 (100%)]\tLoss  0.012165\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9729/10000 (97%)\n",
      "\n",
      "Train Epoch: 34 [30016/60000 (100%)]\tLoss  0.011463\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 35 [30016/60000 (100%)]\tLoss  0.010413\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9730/10000 (97%)\n",
      "\n",
      "Train Epoch: 36 [30016/60000 (100%)]\tLoss  0.009788\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 37 [30016/60000 (100%)]\tLoss  0.009086\n",
      "Test set:\n",
      " Loss: 0.0013\tAccuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 38 [30016/60000 (100%)]\tLoss  0.008569\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9734/10000 (97%)\n",
      "\n",
      "Train Epoch: 39 [30016/60000 (100%)]\tLoss  0.008029\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9730/10000 (97%)\n",
      "\n",
      "Train Epoch: 40 [30016/60000 (100%)]\tLoss  0.007147\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9735/10000 (97%)\n",
      "\n",
      "Train Epoch: 41 [30016/60000 (100%)]\tLoss  0.006606\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9732/10000 (97%)\n",
      "\n",
      "Train Epoch: 42 [30016/60000 (100%)]\tLoss  0.006495\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9737/10000 (97%)\n",
      "\n",
      "Train Epoch: 43 [30016/60000 (100%)]\tLoss  0.005769\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9740/10000 (97%)\n",
      "\n",
      "Train Epoch: 44 [30016/60000 (100%)]\tLoss  0.005370\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9742/10000 (97%)\n",
      "\n",
      "Train Epoch: 45 [30016/60000 (100%)]\tLoss  0.004561\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9747/10000 (97%)\n",
      "\n",
      "Train Epoch: 46 [30016/60000 (100%)]\tLoss  0.004504\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9744/10000 (97%)\n",
      "\n",
      "Train Epoch: 47 [30016/60000 (100%)]\tLoss  0.004339\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9743/10000 (97%)\n",
      "\n",
      "Train Epoch: 48 [30016/60000 (100%)]\tLoss  0.004242\n",
      "Test set:\n",
      " Loss: 0.0014\tAccuracy: 9747/10000 (97%)\n",
      "\n",
      "Train Epoch: 49 [30016/60000 (100%)]\tLoss  0.003498\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9746/10000 (97%)\n",
      "\n",
      "Train Epoch: 50 [30016/60000 (100%)]\tLoss  0.003658\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9748/10000 (97%)\n",
      "\n",
      "Train Epoch: 51 [30016/60000 (100%)]\tLoss  0.003477\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9745/10000 (97%)\n",
      "\n",
      "Train Epoch: 52 [30016/60000 (100%)]\tLoss  0.002990\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 53 [30016/60000 (100%)]\tLoss  0.002462\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9750/10000 (98%)\n",
      "\n",
      "Train Epoch: 54 [30016/60000 (100%)]\tLoss  0.002347\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 55 [30016/60000 (100%)]\tLoss  0.001950\n",
      "Test set:\n",
      " Loss: 0.0015\tAccuracy: 9746/10000 (97%)\n",
      "\n",
      "Train Epoch: 56 [30016/60000 (100%)]\tLoss  0.002426\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9751/10000 (98%)\n",
      "\n",
      "Train Epoch: 57 [30016/60000 (100%)]\tLoss  0.001571\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9746/10000 (97%)\n",
      "\n",
      "Train Epoch: 58 [30016/60000 (100%)]\tLoss  0.001567\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 59 [30016/60000 (100%)]\tLoss  0.001069\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9754/10000 (98%)\n",
      "\n",
      "Train Epoch: 60 [30016/60000 (100%)]\tLoss  0.000875\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9751/10000 (98%)\n",
      "\n",
      "Train Epoch: 61 [30016/60000 (100%)]\tLoss  0.000733\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9758/10000 (98%)\n",
      "\n",
      "Train Epoch: 62 [30016/60000 (100%)]\tLoss  0.000868\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 63 [30016/60000 (100%)]\tLoss  0.002229\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9753/10000 (98%)\n",
      "\n",
      "Train Epoch: 64 [30016/60000 (100%)]\tLoss  0.002137\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9756/10000 (98%)\n",
      "\n",
      "Train Epoch: 65 [30016/60000 (100%)]\tLoss  0.001502\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 66 [30016/60000 (100%)]\tLoss  0.001577\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9759/10000 (98%)\n",
      "\n",
      "Train Epoch: 67 [30016/60000 (100%)]\tLoss  0.001036\n",
      "Test set:\n",
      " Loss: 0.0016\tAccuracy: 9766/10000 (98%)\n",
      "\n",
      "Train Epoch: 68 [30016/60000 (100%)]\tLoss  0.000783\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 69 [30016/60000 (100%)]\tLoss  0.001084\n",
      "Test set:\n",
      " Loss: 0.0019\tAccuracy: 9750/10000 (98%)\n",
      "\n",
      "Train Epoch: 70 [30016/60000 (100%)]\tLoss  0.000333\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9766/10000 (98%)\n",
      "\n",
      "Train Epoch: 71 [30016/60000 (100%)]\tLoss  0.000421\n",
      "Test set:\n",
      " Loss: 0.0019\tAccuracy: 9743/10000 (97%)\n",
      "\n",
      "Train Epoch: 72 [30016/60000 (100%)]\tLoss  0.000217\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 73 [30016/60000 (100%)]\tLoss  0.000177\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9774/10000 (98%)\n",
      "\n",
      "Train Epoch: 74 [30016/60000 (100%)]\tLoss  0.000221\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9771/10000 (98%)\n",
      "\n",
      "Train Epoch: 75 [30016/60000 (100%)]\tLoss  0.000633\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 76 [30016/60000 (100%)]\tLoss  0.000099\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9777/10000 (98%)\n",
      "\n",
      "Train Epoch: 77 [30016/60000 (100%)]\tLoss  0.000199\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9780/10000 (98%)\n",
      "\n",
      "Train Epoch: 78 [30016/60000 (100%)]\tLoss  0.000101\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9774/10000 (98%)\n",
      "\n",
      "Train Epoch: 79 [30016/60000 (100%)]\tLoss  0.000045\n",
      "Test set:\n",
      " Loss: 0.0022\tAccuracy: 9707/10000 (97%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [30016/60000 (100%)]\tLoss  0.000261\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 81 [30016/60000 (100%)]\tLoss  0.000193\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 82 [30016/60000 (100%)]\tLoss  0.000309\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 83 [30016/60000 (100%)]\tLoss  0.000065\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9790/10000 (98%)\n",
      "\n",
      "Train Epoch: 84 [30016/60000 (100%)]\tLoss  0.000159\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9777/10000 (98%)\n",
      "\n",
      "Train Epoch: 85 [30016/60000 (100%)]\tLoss  0.000144\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 86 [30016/60000 (100%)]\tLoss  0.000064\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9790/10000 (98%)\n",
      "\n",
      "Train Epoch: 87 [30016/60000 (100%)]\tLoss  0.000023\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 88 [30016/60000 (100%)]\tLoss  0.000045\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9783/10000 (98%)\n",
      "\n",
      "Train Epoch: 89 [30016/60000 (100%)]\tLoss  0.000048\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9794/10000 (98%)\n",
      "\n",
      "Train Epoch: 90 [30016/60000 (100%)]\tLoss  0.000042\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9794/10000 (98%)\n",
      "\n",
      "Train Epoch: 91 [30016/60000 (100%)]\tLoss  0.000105\n",
      "Test set:\n",
      " Loss: 0.0019\tAccuracy: 9769/10000 (98%)\n",
      "\n",
      "Train Epoch: 92 [30016/60000 (100%)]\tLoss  0.000073\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9800/10000 (98%)\n",
      "\n",
      "Train Epoch: 93 [30016/60000 (100%)]\tLoss  0.000037\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9794/10000 (98%)\n",
      "\n",
      "Train Epoch: 94 [30016/60000 (100%)]\tLoss  0.000033\n",
      "Test set:\n",
      " Loss: 0.0017\tAccuracy: 9798/10000 (98%)\n",
      "\n",
      "Train Epoch: 95 [30016/60000 (100%)]\tLoss  0.000029\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9798/10000 (98%)\n",
      "\n",
      "Train Epoch: 96 [30016/60000 (100%)]\tLoss  0.000420\n",
      "Test set:\n",
      " Loss: 0.0032\tAccuracy: 9664/10000 (97%)\n",
      "\n",
      "Train Epoch: 97 [30016/60000 (100%)]\tLoss  0.000071\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9796/10000 (98%)\n",
      "\n",
      "Train Epoch: 98 [30016/60000 (100%)]\tLoss  0.000030\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9787/10000 (98%)\n",
      "\n",
      "Train Epoch: 99 [30016/60000 (100%)]\tLoss  0.000039\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9795/10000 (98%)\n",
      "\n",
      "Train Epoch: 100 [30016/60000 (100%)]\tLoss  0.000050\n",
      "Test set:\n",
      " Loss: 0.0018\tAccuracy: 9797/10000 (98%)\n",
      "\n",
      "CPU times: user 11min 30s, sys: 13.6 s, total: 11min 43s\n",
      "Wall time: 11min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1,101):\n",
    "    model.train()\n",
    "    train(epoch, model, train_dl)\n",
    "    test(model, test_dl, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH / \"ae_classifier.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = data.DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, c = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAABTCAYAAADjsjsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA4ZJREFUeJzt280rbHEcx/H3uV2NhTxlSjqUKJMkCxs2Cgn5A5T/wMLSjpKNIisW4k9goSQbpVgoSja6dyEPjRRh4ZaIzl2dc8zcO5nf3K/z4H5fG+OcM+Pbp8/PzJw5YzmOg5LxLewBvhINU5CGKUjDFKRhCtIwBWmYgjRMQRqmIA1T0HfTOyQSCSeZTH7GLJF0e3vL8/Ozlc+xxmEmk0nS6bT5VDFl23bex+oyF6RhCtIwBWmYgjRMQRqmIA1TkIYpSMMUpGEK0jAFaZiCjE90FGJ1dRWA5eVlAGpqarx9xcXFAIyMjABQXV0NQGNjYxCjidJmCrJML4+xbdsxPQVXX18PwPn5+YfHlpaWAtDc3Gz0N3Kpra0FYHx8HID29naj+9u2TTqdzut8pjZTkIYpKJAnoJWVFQCOj4+BzCV8cnICwNHREQA7OzsA7O/vA1BXVwfA5eVlzscvKioCoKqqCoDr62tvn/s47nI3XeYmtJmCAmlmT09Pxs/3+vv7M35/eHgA/Ka6TTo4OMj5+IlEAoCmpiYAUqmUt+/+/h6AhoaGgmY3oc0UFEgzTVRUVADQ3d2dsf1vrc62trYG+O0GaG1tBWB4eFhqxJy0mYIi18xC3NzcADA6OgrA+zcik5OTAFRWVn76HNpMQV+imYuLi4Df0PLycm+f+wwfBG2moFg3c29vD4CZmZmM7evr697tlpaWwObRZgrSMAXFeplvbm4C8PLyAkBvby8AHR0docyjzRQUy2Y+PT0BsLW1BfgnOqampgD/lFzQtJmCYtnM2dlZwD9NNzAwAEBnZ2doM4E2U1RsmrmxseHdnp6eBqCsrAyAiYmJUGbKps0UFPlm3t3dATA2NuZte319BWBwcBAI73VlNm2mIA1TUGSX+dvbG+B/enl2dubtcy/qcp+IokKbKSiyzTw9PQXg8PDwj33z8/NAMJ+Fm9BmCopcMy8uLgDo6+vL2D43N+fdHhoaCnSmfGkzBUWumUtLS4DfUFdXV5d327LyuvY0cNpMQZFp5u7uLgALCwshT1I4baagyDTT/Qz88fExY7v7bqekpCTwmUxpMwVpmIIis8yztbW1AbC9vQ0Ec0ngv9JmCgrkG2pxpt9QC4lxmHF4iSLp6urqZ77HGi9zy7J+AP9Tor8cx0l9fFgBYarc9H+mIA1TkIYpSMMUpGEK0jAFaZiCNExBGqag3yGbx31erdTGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 80x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(w, (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class of original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitToClass(nn.Module):\n",
    "    def __init__(self, data, target_class):\n",
    "        super().__init__()\n",
    "        self._loss = None\n",
    "        self.target_class = torch.tensor([target_class]).to(device)\n",
    "        self.w = nn.Parameter(data)\n",
    "        self.optim = optim.Adam(self.parameters(), lr=1e-4)\n",
    "        \n",
    "    def forward(self):\n",
    "        out = model(self.w)\n",
    "        return out\n",
    "    \n",
    "    def loss(self, out):\n",
    "        self._loss = F.nll_loss(out, self.target_class)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to change class of image to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.237902641296387\n",
      "0.04878091812133789\n",
      "0.01614236831665039\n",
      "0.007331371307373047\n",
      "0.0038385391235351562\n",
      "0.0021462440490722656\n",
      "0.0012426376342773438\n",
      "0.0007271766662597656\n",
      "0.0004315376281738281\n",
      "0.000255584716796875\n",
      "0.00015211105346679688\n",
      "9.012222290039062e-05\n",
      "5.245208740234375e-05\n",
      "3.147125244140625e-05\n",
      "1.8596649169921875e-05\n",
      "1.1444091796875e-05\n",
      "6.67572021484375e-06\n",
      "3.814697265625e-06\n",
      "2.86102294921875e-06\n",
      "1.9073486328125e-06\n",
      "9.5367431640625e-07\n",
      "9.5367431640625e-07\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "m = FitToClass(w, 8).to(device)\n",
    "m.train()\n",
    "\n",
    "for i in range(1, 30_001):\n",
    "    m.optim.zero_grad()\n",
    "    out = m()\n",
    "    loss = m.loss(out)\n",
    "    loss.backward()\n",
    "    m.optim.step()\n",
    "    if i % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = m.w.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict class of target image with trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(target_img)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAABTCAYAAADjsjsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAv1JREFUeJzt3DEvJHEcxvHvXC6hECKxiWISIZGsUjRqQanTiU6hEJ14ARq9UGkoaTRegEYnGnEXBZEVCQnCRmjMFZeZu4sjM+6xM7P3fKrN7OzOz5NnZPc/QxBFEabxJe8BmonDFHKYQg5TyGEKOUwhhynkMIUcppDDFPqa9QUtLS1RpVL5jFkK6fr6mufn5yDNvpnDrFQq1Gq17FOVVBiGqff1aS7kMIUcppDDFHKYQg5TyGEKOUwhhynkMIUcppDDFMq80PEvdnd3AXh5eUm2DQ8PA9DV1dXIUT6FmynUkGaOjY0BcHZ2BkAQ/FoePDk5AaCvrw+Anp4eACYnJwHY2toCYHp6OnlNZ2cnADs7OwDU63UAZmdnAbi7u3v1/gsLC6of501uppDDFAqy3gUXhmH0GSvtp6enACwtLQFweHgIQFtbGwD39/fJvvFzsfHxcQC6u7sB2NjYSJ7r6OgAYH9/H4CBgYFMc4VhSK1WS3XZws0UauhHo/f09vYCsL6+/s/v9fT0lDy+ubkBsjfyI9xMocI0U+no6Ch5PDMz07DjuplCTdXM+IP9782cn59v2PHdTKGmaubm5maux3czhZqimUNDQwBUq1UAjo+Pc5nDzRRymEKlPs0PDg4AeHx8BGB5eTnPcdxMpVI3M16Nb29vB2BiYiLPcdxMpVI38+rqCoDt7e2cJ/nJzRQqZTPja+1TU1MADA4O5jlOws0UKk0zFxcXk8fxxbW1tbW8xvkrN1PIYQoV/jRfWVkBYG9vL9l2e3ub1zjvcjOFCt/Mubm5V9uK+r+Y3EyhwjYzvrUw9vDwkNMk6bmZQoVr5uXlJQDn5+d/bI/vhisyN1OocM0cGRnJe4QPczOFCtfM1tZWAEZHRwHo7+/Pc5xM3EwhhylUuNM8vvk/XkVfXV3Nc5xM3EyhwjWzqIsYabiZQpnDLMPXOqWLi4vvaffN/BdqQRB8A/6nROtRFFXT7Jg5THubf2cKOUwhhynkMIUcppDDFHKYQg5TyGEK/QAQG6FabjJJSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 80x80 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(target_img.view(-1, 1, 28, 28).clamp(0, 1).data.cpu().numpy(), (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
